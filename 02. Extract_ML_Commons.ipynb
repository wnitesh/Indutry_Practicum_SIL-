{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24e71388",
   "metadata": {},
   "source": [
    "## ML Commons Data Source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "459ad061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a751cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_directory = os.getcwd()\n",
    "os.chdir(current_directory + '/language_source')\n",
    "lang_list = glob.glob('*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b445a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_corpus = pd.DataFrame()\n",
    "\n",
    "for lang in tqdm.tqdm(lang_list):\n",
    "    temp_df = pd.read_csv(lang)\n",
    "    temp_word_list = pd.DataFrame(temp_df['WORD'].unique())\n",
    "    temp_word_list.rename(columns={0:lang}, inplace=True)\n",
    "    word_corpus = pd.concat([word_corpus, temp_word_list], axis=1)\n",
    "\n",
    "word_corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f218dd",
   "metadata": {},
   "source": [
    "#### Rename Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6c6685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2db86212",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_list_df = pd.DataFrame(np.array(lang_list))\n",
    "lang_list_df.rename(columns={0:'raw_input'}, inplace=True)\n",
    "\n",
    "\n",
    "lang_codes = []\n",
    "for lang in lang_list:\n",
    "    x = lang.split('_')\n",
    "    lang_codes.append(x[0])\n",
    "\n",
    "lang_codes_df = pd.DataFrame(np.array(lang_codes))\n",
    "lang_codes_df.rename(columns={0:'lang_code'}, inplace=True)\n",
    "\n",
    "lang_merged = pd.concat([lang_list_df,lang_codes_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a01962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_langs = pd.read_excel('Language_mappings.xlsx', header=None )\n",
    "full_langs.rename(columns={0:'language', 1:'lang_code'}, inplace=True)\n",
    "full_langs.drop_duplicates(subset='lang_code', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0912a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge two DataFrames\n",
    "lang_name_list = lang_merged.merge(full_langs, how='left', on='lang_code')\n",
    "col_names = lang_name_list['language'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89607a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename word corpus columns\n",
    "word_corpus.columns = col_names\n",
    "word_corpus.to_csv('word_corpus.csv', encoding='utf_8_sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f7ab5a",
   "metadata": {},
   "source": [
    "#### Using M2M100 Hugging Face model to map words in different language to english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb1de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('word_corpus.csv')\n",
    "m2m_language_mappings = pd.read_excel('m2m mapping.xlsx')\n",
    "mlc_language_codes = pd.read_excel('language_code_mapping.xlsx')\n",
    "\n",
    "df.replace(np.nan,'',regex=True, inplace=True)\n",
    "df.drop(columns=['English'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1ea4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert words from non-english language to english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47317bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4719886",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    trans_words = {}\n",
    "    word_list = []\n",
    "    if mlc_language_codes['Language'].str.contains(column).sum()>0:\n",
    "        lang_code = mlc_language_codes.loc[mlc_language_codes[mlc_language_codes['Language']==column].index[0], 'lang_code']\n",
    "        if m2m_language_mappings['lang_code'].str.contains(lang_code).sum()>0:\n",
    "            for word in tqdm(df[column]):\n",
    "                if word != '':\n",
    "                    word = word\n",
    "                    tokenizer.src_lang = lang_code\n",
    "                    encoded_src_lang = tokenizer(word, return_tensors=\"pt\")\n",
    "                    generated_tokens = model.generate(**encoded_src_lang, forced_bos_token_id=tokenizer.get_lang_id(\"en\"))\n",
    "                    word_list.append(tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0])\n",
    "    trans_words[column] = word_list\n",
    "    converted_words = pd.DataFrame(trans_words)\n",
    "    converted_words.to_csv(column)\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a933ff66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.apply(lambda x: pd.Series(x.dropna().values)).fillna('')\n",
    "df.to_csv(\"nan_shifted_up_word_corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78cfb737",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge translated files with original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdfe53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import word corpus\n",
    "df = pd.read_csv('nan_shifted_up_word_corpus.csv')\n",
    "\n",
    "#drop additional index column\n",
    "df = df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc913ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(current_directory + '/lang_translated_files')\n",
    "\n",
    "translated_files = glob.glob('*')\n",
    "\n",
    "#Create dataframe of english words\n",
    "\n",
    "df_english_words = pd.DataFrame()\n",
    "\n",
    "for file in translated_files:\n",
    "    temp_df = pd.read_csv(file, names=['index', 'english_words'])\n",
    "    temp_df = temp_df.iloc[1:,1:]\n",
    "    df_english_words = pd.concat([df_english_words,temp_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates from the data\n",
    "df_english_words = df_english_words.drop_duplicates()\n",
    "df_english_words.dropna(inplace=True)\n",
    "df_english_words.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bd8b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create merged dataframe of original and english translated words\n",
    "\n",
    "d = {}\n",
    "\n",
    "for file in translated_files:\n",
    "    temp_df = df[[file]]\n",
    "    eng_df = pd.read_csv(file)\n",
    "    eng_df = eng_df.rename(columns={file:file+'_eng'})\n",
    "    d[file] = pd.concat([eng_df,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba920038",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_words_df = pd.DataFrame()\n",
    "\n",
    "for file in tqdm(translated_files):\n",
    "    temp_df = df_english_words.merge(d[file], how='left', left_on = 'english_words', right_on = (file + '_eng'))\n",
    "    temp_df = temp_df.groupby(['english_words'])[file].apply(lambda x: '/'.join(x.astype(str))).reset_index()\n",
    "    temp_df = temp_df.iloc[:,1:]\n",
    "    translated_words_df = pd.concat([translated_words_df,temp_df], axis=1)\n",
    "\n",
    "os.chdir(current_directory)\n",
    "translated_words_df.replace('nan',\"\", inplace=True)\n",
    "translated_words_df.to_csv('mlcommons_word_corpus_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
